<feed xmlns="http://www.w3.org/2005/Atom"><title type="text">黑客新闻摘要&lt;/stitle>; &lt;id>;https://hackernews.betacat.io/feed.xml&lt;/id>; &lt;updated>;2023-06-11T04:02:10.813966Z&lt;/updated>; &lt;link href=&quot;{ &#39;https://hackernews.betacat.io&#39;}&quot;/>; &lt;link href=&quot;https://hackernews.betacat.io/feed.xml&quot; rel=&quot;self&quot;/>; &lt;author>; &lt;name>;polyrabbit&lt;/名称>; &lt;uri>;https://github.com/polyrabbit/&lt;/uri>; &lt;/author>; &lt;generator>;Werkzeug&lt;/generator>; &lt;entry xml:base=&quot;https://hackernews.betacat.io/feed. xml&quot;>; &lt;title type=&quot;text&quot;>;梭子鱼敦促更换而不是修补其电子邮件安全网关&lt;/stitle>; &lt;id>;https://krebsonsecurity.com/2023/06/barracuda-urges-replacing-not-patching -its-email-security-gateways/&lt;/id>; &lt;更新>;2023-06-10T21:01:31.030792Z&lt;/更新>; &lt;link href=&quot;https://krebsonsecurity.com/2023/06/barracuda-urges -replacing-not-patching-its-email-security-gateways/&quot;/>; &lt;author>; &lt;name>;LinuxBender&lt;/name>; &lt;uri>;https://news.ycombinator.com/user?id=LinuxBender&lt;/uri >; &lt;/author>; &lt;content type=&quot;html&quot;>;&lt;img src=&quot;https://krebsonsecurity.com/b-magnet/11.jpg&quot; style=&quot;宽度：220px；高度：198px；&quot; />;&lt;br />;Barracuda Networks 已敦促客户更换其电子邮件安全网关 (ESG) 设备，而不是在先前未知的漏洞被攻击者利用后仅应用软件更新。该公司表示，该恶意软件是在允许攻击者对设备进行持续后门访问的设备子集上识别出来的，并且在某些系统上发现了数据泄露的证据。 &lt;a href=&quot;https://hackernews.betacat.io/#barracuda-urges-replacing-not-patching-its-email-security-gateways&quot; target=&quot;_blank&quot;>;[摘要]&lt;/a>; &lt;a href =&quot;https://news.ycombinator.com/item?id=36274525&quot; target=&quot;_blank&quot;>;[评论]&lt;/a>;&lt;/content>; &lt;/entry>; &lt;entry xml:base=&quot;https:// hackernews.betacat.io/feed.xml&quot;>; &lt;title type=&quot;text&quot;>;为什么在 Erlang VM 上进行机器学习？&lt;/stitle>; &lt;id>;https://underjord.io/why-ml-on-erlang。 html&lt;/id>; &lt;更新>;2023-06-10T23:01:31.031360Z&lt;/更新>; &lt;link href=&quot;https://underjord.io/why-ml-on-erlang.html&quot;/>; &lt;作者>; &lt;名称>;法维克&lt;/名称>; &lt;uri>;https://news.ycombinator.com/user?id=法维克&lt;/uri>; &lt;/author>; &lt;content type=&quot;html&quot;>;&lt;img src=&quot;https:/ /underjord.io/img/logo2.svg&quot; style=&quot;宽度：220px；高度：221px；&quot; />;&lt;br />;作者讨论了他们对机器学习及其实际应用的看法，特别是在实时字幕和数据处理等实用任务中。他们还比较了在机器学习项目中使用 Python 和 Elixir 的优缺点。 &lt;a href=&quot;https://hackernews.betacat.io/#why-do-ml-on-the-erlang-vm&quot; target=&quot;_blank&quot;>;[摘要]&lt;/a>; &lt;a href=&quot;https: //news.ycombinator.com/item?id=36255546&quot; target=&quot;_blank&quot;>;[评论]&lt;/a>;&lt;/content>; &lt;/entry>; &lt;entry xml:base=&quot;https://hackernews.betacat. io/feed.xml&quot;>; &lt;title type=&quot;text&quot;>;Gren – 榆树叉子&lt;/stitle>; &lt;id>;https://gren-lang.org/&lt;/id>; &lt;updated>;2023-06-10T21： 01:31.031821Z&lt;/updated>; &lt;link href=&quot;https://gren-lang.org/&quot;/>; &lt;author>; &lt;name>;jgilias&lt;/name>; &lt;uri>;https://news.ycombinator.com/ user?id=jgilias&lt;/uri>; &lt;/author>; &lt;content type=&quot;html&quot;>;&lt;img src=&quot;https://gren-lang.org/big_icon.png&quot; style=&quot;宽度：220px；高度：220px ;&quot; />;&lt;br />;Gren 是一种函数式编程语言，具有精心管理的副作用和强大的静态类型系统。该语言由一些具有人类可读名称的概念组成，这些概念很好地组合在一起，因此您可以事半功倍。用 Gren 编写的程序很简单，很少或没有运行时异常，并且使用起来很有趣。 &lt;a href=&quot;https://hackernews.betacat.io/#gren-an-elm-fork&quot; target=&quot;_blank&quot;>;[摘要]&lt;/a>; &lt;a href=&quot;https://news.ycombinator。 com/item?id=36274813&quot; target=&quot;_blank&quot;>;[评论]&lt;/a>;&lt;/content>; &lt;/entry>; &lt;entry xml:base=&quot;https://hackernews.betacat.io/feed.xml&quot; >; &lt;title type=&quot;text&quot;>;花生酱水母时间&lt;/stitle>; &lt;id>;https://gebir.ge/blog/peanut-butter-jellyfin-time/&lt;/id>; &lt;updated>;2023-06-10T22 :01:31.032283Z&lt;/updated>; &lt;link href=&quot;https://gebir.ge/blog/peanut-butter-jellyfin-time/&quot;/>; &lt;author>; &lt;name>;makrelmad&lt;/name>; &lt;uri>;https ://news.ycombinator.com/user?id=makrelmad&lt;/uri>; &lt;/author>; &lt;content type=&quot;html&quot;>;Jellyfin 是一个由志愿者构建的媒体解决方案，可让您控制自己的媒体。它可以安装在任何主机上，没有任何附加条件。我们总是可以通过观察其他人如何做事来学习 3。如果您对代码不满意，可以从 github.com/seasoned 下载源代码。我一直致力于呈现的 rce 链，以展示 &lt;a href=&quot;https://hackernews.betacat.io/#peanut-butter-jellyfin-time&quot; target=&quot;_blank&quot;>;[summary ]&lt;/a>;&lt;/content>; &lt;/entry>; &lt;entry xml:base=&quot;https://hackernews.betacat.io/feed.xml&quot;>; &lt;title type=&quot;text&quot;>;梅赛德斯在自动驾驶方面击败特斯拉加州&lt;/stitle>; &lt;id>;https://www.theregister.com/2023/06/09/mercedes_california_tesla/&lt;/id>; &lt;updated>;2023-06-10T14:01:31.032683Z&lt;/updated>; &lt;link href =&quot;https://www.theregister.com/2023/06/09/mercedes_california_tesla/&quot;/>; &lt;author>; &lt;name>;belter&lt;/name>; &lt;uri>;https://news.ycombinator.com/user?id =belter&lt;/uri>; &lt;/author>; &lt;content type=&quot;html&quot;>;&lt;img src=&quot;https://regmedia.co.uk/2023/06/09/californiahighway.jpg&quot; style=&quot;width: 220px;高度：220px；&quot; />;&lt;br />;梅赛德斯-奔驰在加利福尼亚州首次获得授权，可以向公众出售或租赁带有自动驾驶系统的车辆，但有限制。 DRIVE PILOT 系统是一个 3 级自动化系统，可以在某些情况下主动执行驾驶任务，而无需人类驾驶员的主动控制，尽管驾驶员必须留在方向盘后面以在出现提示时接管。 &lt;a href=&quot;https://hackernews.betacat.io/#mercedes-beats-tesla-to-autonomous-driving-in-california&quot; target=&quot;_blank&quot;>;[摘要]&lt;/a>; &lt;a href=&quot; https://news.ycombinator.com/item?id=36270413&quot; target=&quot;_blank&quot;>;[评论]&lt;/a>;&lt;/content>; &lt;/entry>; &lt;entry xml:base=&quot;https://hackernews. betacat.io/feed.xml&quot;>; &lt;title type=&quot;text&quot;>;纽约市将向前往市区的司机收费&lt;/stitle>; &lt;id>;https://www.cnn.com/2023/06/10/business/ congestion-pricing-new-york-city-transportation/index.html&lt;/id>; &lt;updated>;2023-06-10T15:01:31.033047Z&lt;/updated>; &lt;link href=&quot;https://www.cnn.com /2023/06/10/business/congestion-pricing-new-york-city-transportation/index.html&quot;/>; &lt;author>; &lt;name>;rntn&lt;/name>; &lt;uri>;https://news.ycombinator.com /user?id=rntn&lt;/uri>; &lt;/author>; &lt;content type=&quot;html&quot;>;&lt;img src=&quot;https://media.cnn.com/api/v1/images/stellar/prod/230530162322-04 -congestion-pricing-new-york-city-restricted.jpg?c=16x9&amp;q=h_720,w_1280,c_fill&quot; style=&quot;宽度：220px；高度：147px；&quot; />;&lt;br />;拜登总统的政府允许纽约市实施一项名为“拥堵收费”的收费计划，向进入曼哈顿下城的司机收费，建议在高峰时段收费 9 至 23 美元。收费旨在减少拥堵，改善公共交通，并产生收入以资助 150 亿美元的未来投资，以实现城市公共交通系统的现代化。 &lt;a href=&quot;https://hackernews.betacat.io/#new-york-city-will-charge-drivers-going-downtown&quot; target=&quot;_blank&quot;>;[摘要]&lt;/a>; &lt;a href=&quot; https://news.ycombinator.com/item?id=36270597&quot; target=&quot;_blank&quot;>;[评论]&lt;/a>;&lt;/content>; &lt;/entry>; &lt;entry xml:base=&quot;https://hackernews. betacat.io/feed.xml&quot;>; &lt;title type=&quot;text&quot;>;列出一项任务，完成它，划掉它&lt;/stitle>; &lt;id>;https://www.oliverburkeman.com/onething&lt;/id>; &lt;更新>;2023-06-10T16:01:31.033471Z&lt;/更新>; &lt;link href=&quot;https://www.oliverburkeman.com/onething&quot;/>; &lt;author>; &lt;name>;Tomte&lt;/name>; &lt;uri>;https //news.ycombinator.com/user?id=Tomte&lt;/uri>; &lt;/author>; &lt;content type=&quot;html&quot;>;&lt;img src=&quot;https://static.wixstatic.com/media/053ea9_019073577d0445b6b521687231c3166f~mv2 .png/v1/fill/w_268,h_247,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/1621444132.png&quot; style=&quot;宽度：220px；高度：203px；&quot; />;&lt;br />;作者反思了他们在紧急情况下保持冷静和机智的能力，将其归因于没有自我怀疑和清楚需要做什么。他们认为，提高工作效率的关键不是尝试同时处理多项任务，而是一次专注于一件事，然后更好地决定下一步该做什么。 &lt;a href=&quot;https://hackernews.betacat.io/#list-one-task-do-it-cross-it-out&quot; target=&quot;_blank&quot;>;[摘要]&lt;/a>; &lt;a href=&quot; https://news.ycombinator.com/item?id=36253882&quot; target=&quot;_blank&quot;>;[评论]&lt;/a>;&lt;/content>; &lt;/entry>; &lt;entry xml:base=&quot;https://hackernews. betacat.io/feed.xml&quot;>; &lt;title type=&quot;text&quot;>;一艘载有难民的船消失了——一个电话解开了谜团&lt;/stitle>; &lt;id>;https://apnews.com/article/rohingya-investigation- missing-boat-refugees-bangladesh-myanmar-migration-1b94b4472a42b26eb066bef47b7bcf7e&lt;/id>; &lt;更新>;2023-06-11T03:01:31.033865Z&lt;/更新>; &lt;link href=&quot;https://apnews.com/article/rohingya -investigation-missing-boat-refugees-bangladesh-myanmar-migration-1b94b4472a42b26eb066bef47b7bcf7e&quot;/>; &lt;author>; &lt;name>;gmays&lt;/name>; &lt;uri>;https://news.ycombinator.com/user?id=gmays&lt;/ uri>; &lt;/author>; &lt;content type=&quot;html&quot;>;&lt;img src=&quot;https://storage.googleapis.com/afs-prod/media/7911338329b747e9ab943edab177e4f5/1920.webp&quot; style=&quot;width: 220px; 高度: 124 像素；&quot; />;&lt;br />;罗兴亚难民为了逃避缅甸和孟加拉国肮脏的营地的迫害和暴力，正在进行一场生死赌博，出海。尽管存在危险，但在政府或海事当局几乎没有帮助的情况下，它们经常被遗弃并死在水面上。 &lt;a href=&quot;https://hackernews.betacat.io/#a-boat-with-refugees-vanished-a-phone-call-untangled-the-mystery&quot; target=&quot;_blank&quot;>;[摘要]&lt;/a >; &lt;a href=&quot;https://news.ycombinator.com/item?id=36274739&quot; target=&quot;_blank&quot;>;[评论]&lt;/a>;&lt;/content>; &lt;/entry>; &lt;entry xml:base=&quot; https://hackernews.betacat.io/feed.xml&quot;>; &lt;title type=&quot;text&quot;>;MusicGen：简单可控的音乐生成&lt;/stitle>; &lt;id>;https://ai.honu.io/papers/musicgen /&lt;/id>; &lt;updated>;2023-06-10T17:01:31.034228Z&lt;/updated>; &lt;link href=&quot;https://ai.honu.io/papers/musicgen/&quot;/>; &lt;作者>; &lt;名称>; og_kalu&lt;/name>; &lt;uri>;https://news.ycombinator.com/user?id=og_kalu&lt;/uri>; &lt;/author>; &lt;content type=&quot;html&quot;>;文章介绍了MusicGen，一个单一的语言模型，可以在以文本描述或旋律特征为条件的同时生成高质量的音乐样本。它优于标准文本到音乐基准测试中的其他评估基线。 &lt;a href=&quot;https://hackernews.betacat.io/#musicgen-simple-and-controllable-music-generation&quot; target=&quot;_blank&quot;>;[摘要]&lt;/a>; &lt;a href=&quot;https:// news.ycombinator.com/item?id=36271926&quot; target=&quot;_blank&quot;>;[评论]&lt;/a>;&lt;/content>; &lt;/entry>; &lt;entry xml:base=&quot;https://hackernews.betacat.io/ feed.xml&quot;>; &lt;title type=&quot;text&quot;>;Intel x86-SIMD-sort (AVX-512) 性能分析&lt;/stitle>; &lt;id>;https://github.com/Vultapher/sort-research-rs /blob/main/writeup/intel_avx512/text.md&lt;/id>; &lt;更新>;2023-06-10T19:01:31.034595Z&lt;/更新>; &lt;link href=&quot;https://github.com/Vultapher/sort- research-rs/blob/main/writeup/intel_avx512/text.md&quot;/>; &lt;author>; &lt;name>;Twirrim&lt;/name>; &lt;uri>;https://news.ycombinator.com/user?id=Twirrim&lt;/uri >; &lt;/author>; &lt;content type=&quot;html&quot;>;&lt;img src=&quot;https://raw.githubusercontent.com/Vultapher/sort-research-rs/main/writeup/intel_avx512/assets/hot-u64-10k- windows.png&quot; style=&quot;宽度：220px；高度：289px；&quot; />;&lt;br />;英特尔发布了一个新的 AVX-512 排序库，它比其他通用排序实现要快得多。然而，基准测试很复杂，不同实现的性能可能因输入大小和模式等因素而异。 &lt;a href=&quot;https://hackernews.betacat.io/#a-performance-analysis-of-intel-x86-simd-sort-avx-512&quot; target=&quot;_blank&quot;>;[摘要]&lt;/a>; &lt; a href=&quot;https://news.ycombinator.com/item?id=36273544&quot; target=&quot;_blank&quot;>;[评论]&lt;/a>;&lt;/content>; &lt;/entry>; &lt;entry xml:base=&quot;https: //hackernews.betacat.io/feed.xml&quot;>; &lt;title type=&quot;text&quot;>;硬盘驱动器容量的巨大飞跃：32 TB HAMR 驱动器即将推出，40 TB 即将推出&lt;/stitle>; &lt;id>;https://www .anandtech.com/show/18901/big-leap-for-hdds-32-tb-hamr-drive-is-coming-40tb-on-horizo​​n&lt;/id>; &lt;更新>;2023-06-10T23:01:31.034946 Z&lt;/updated>; &lt;link href=&quot;https://www.anandtech.com/show/18901/big-leap-for-hdds-32-tb-hamr-drive-is-coming-40tb-on-horizo​​n&quot; />; &lt;author>; &lt;name>;walterbell&lt;/name>; &lt;uri>;https://news.ycombinator.com/user?id=walterbell&lt;/uri>; &lt;/author>; &lt;content type=&quot;html&quot;>;&lt;img src =&quot;https://images.anandtech.com/doci/18901/HAMR-actuator-head-and-laser-illustration-hero_678x452.jpg&quot; style=&quot;宽度：220px；高度：124px；&quot; />;&lt;br />;希捷将推出采用热辅助磁记录 (HAMR) 技术的下一代硬盘，首款商用 HAMR 硬盘将于 2023 年第三季度提供 32TB 的容量。新的记录​​技术将使相对较快的容量增加到 40 TB，大容量 HAMR HDD 将与尚未发布的 24 TB 和 28 TB 驱动器共存。 &lt;a href=&quot;https://hackernews.betacat.io/#big-leap-for-hard-drive-capacities-32-tb-hamr-drives-due-soon-40tb-on-horizo​​n&quot; target=&quot;_blank &quot;>;[总结]&lt;/a>; &lt;a href=&quot;https://news.ycombinator.com/item?id=36253499&quot; target=&quot;_blank&quot;>;[评论]&lt;/a>;&lt;/content>; &lt;/entry >; &lt;entry xml:base=&quot;https://hackernews.betacat.io/feed.xml&quot;>; &lt;title type=&quot;text&quot;>;许可对于解决 AI 风险既不可行也无效&lt;/stitle>; &lt;id>;https: //aisnakeoil.substack.com/p/licensing-is-neither-feasible-nor&lt;/id>; &lt;更新>;2023-06-10T14:01:31.035394Z&lt;/更新>; &lt;link href=&quot;https://aisnakeoil .substack.com/p/licensing-is-neither-feasible-nor&quot;/>; &lt;作者>; &lt;name>;headalgorithm&lt;/name>; &lt;uri>;https://news.ycombinator.com/user?id=headalgorithm&lt;/ uri>; &lt;/author>; &lt;content type=&quot;html&quot;>;&lt;img src=&quot;https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https %3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4239d7c6-4f55-4254-91f2-20b9b2bec77e_1118x639.jpeg&quot; style=&quot;width: 220px; height: 119px;&quot; />;&lt;br />;这篇文章讨论了将不扩散作为使 AI 更安全的一种方式的想法，但认为许可和执法将是困难且无效的。相反，作者建议一个多元化的群体学术界、公司和非政府组织应该开发和评估最先进的模型来应对人工智能风险。&lt;a href=&quot;https://hackernews.betacat.io/#licensing-is-neither-feasible-nor-effective -for-addressing-ai-risks&quot; target=&quot;_blank&quot;>;[总结]&lt;/a>; &lt;a href=&quot;https://news.ycombinator.com/item?id=36270303&quot; target=&quot;_blank&quot;>;[ comments]&lt;/a>;&lt;/content>; &lt;/entry>; &lt;entry xml:base=&quot;https://hackernews.betacat.io/feed.xml&quot;>; &lt;title type=&quot;text&quot;>;Fluent – 一个本地化系统听起来自然的翻译&lt;/stitle>; &lt;id>;https://projectfluent.org/&lt;/id>; &lt;updated>;2023-06-11T01:01:31.035785Z&lt;/updated>; &lt;link href=&quot;https://projectfluent .org/&quot;/>; &lt;author>; &lt;name>;croes&lt;/name>; &lt;uri>;https://news.ycombinator.com/user?id=croes&lt;/uri>; &lt;/author>; &lt;content type=&quot;html&quot; >;Fluent 是一个本地化系统，它通过使用多个类别的标识符和变体来简化翻译。它还包括其他消息可以引用的术语，以实现一致性和品牌修改。 &lt;a href=&quot;https://hackernews.betacat.io/#fluent-a-localization-system-for-natural-sounding-translations&quot; target=&quot;_blank&quot;>;[摘要]&lt;/a>; &lt;a href=&quot; https://news.ycombinator.com/item?id=36276791&quot; target=&quot;_blank&quot;>;[评论]&lt;/a>;&lt;/content>; &lt;/entry>; &lt;entry xml:base=&quot;https://hackernews. betacat.io/feed.xml&quot;>; &lt;title type=&quot;text&quot;>;将愚蠢的推文变成楔形文字平板电脑&lt;/stitle>; &lt;id>;https://dumbcuneiform.com/&lt;/id>; &lt;updated>;2023-06-10T23 :01:31.036130Z&lt;/updated>; &lt;link href=&quot;https://dumbcuneiform.com/&quot;/>; &lt;author>; &lt;name>;cainxinth&lt;/name>; &lt;uri>;https://news.ycombinator.com/user ?id=cainxinth&lt;/uri>; &lt;/author>; &lt;content type=&quot;html&quot;>;&lt;img src=&quot;https://dumbcuneiform.com/content/polyglot/images/intro-image.jpg&quot; style=&quot;宽度： 220 像素；高度：113 像素；&quot; />;&lt;br />;这篇文章介绍了一种服务，该服务可以创建手掌大小的粘土板，上面刻有楔形文字以表示短消息，例如情书或推文。这些平板电脑是手工制作的，需要几周的时间来制作和运送。 &lt;a href=&quot;https://hackernews.betacat.io/#turn-dumb-tweets-into-cuneiform-tablets&quot; target=&quot;_blank&quot;>;[摘要]&lt;/a>; &lt;a href=&quot;https:// news.ycombinator.com/item?id=36275974&quot; target=&quot;_blank&quot;>;[评论]&lt;/a>;&lt;/content>; &lt;/entry>; &lt;entry xml:base=&quot;https://hackernews.betacat.io/ feed.xml&quot;>; &lt;title type=&quot;text&quot;>;显示 HN：Bloop – 使用 LLM 代理回答有关您的代码的问题&lt;/stitle>; &lt;id>;https://github.com/BloopAI/bloop&lt;/id>; &lt;更新>;2023-06-10T19:01:31.036518Z&lt;/更新>; &lt;link href=&quot;https://github.com/BloopAI/bloop&quot;/>; &lt;author>; &lt;name>;louiskw&lt;/name>; &lt;uri>;https //news.ycombinator.com/user?id=louiskw&lt;/uri>; &lt;/author>; &lt;content type=&quot;html&quot;>;&lt;img src=&quot;https://camo.githubusercontent.com/ba0e103fefac552c592f7bf6aec3d2e7b6d1ef57160355eea41ba6c57c9e6b6c/68747470733a 2f2f6173736574732e626c6f6f702e61692f626c6f6f705f6769746875625f6c6f676f5f6c696768742e706e67&quot; 风格=&quot;宽度：220px；高度：83px；&quot; />;&lt;br />;Bloop 是一个开发者助手，它使用 GPT-4 来回答有关代码库的问题。它可以使用自然语言、正则表达式和过滤查询来搜索本地和远程存储库，以提高处理大型代码库时的效率。 &lt;a href=&quot;https://hackernews.betacat.io/#show-hn-bloop-answer-questions-about-your-code-with-an-llm-agent&quot; target=&quot;_blank&quot;>;[摘要]&lt; /a>; &lt;a href=&quot;https://news.ycombinator.com/item?id=36260961&quot; target=&quot;_blank&quot;>;[评论]&lt;/a>;&lt;/content>; &lt;/entry>; &lt;entry xml:base =&quot;https://hackernews.betacat.io/feed.xml&quot;>; &lt;title type=&quot;text&quot;>;展示HN：用600行C89编写的RISC-V核心&lt;/stitle>; &lt;id>;https://github .com/mnurzia/rv&lt;/id>; &lt;更新>;2023-06-10T14:01:31.036898Z&lt;/更新>; &lt;link href=&quot;https://github.com/mnurzia/rv&quot;/>; &lt;作者>; &lt;名称>;mnurzia&lt;/name>; &lt;uri>;https://news.ycombinator.com/user?id=mnurzia&lt;/uri>; &lt;/author>; &lt;content type=&quot;html&quot;>;&lt;img src=&quot;https:// opengraph.githubassets.com/dcf660424564184977944dac397949ab3da745131b6b71fec632a3cb365bf3d6/mnurzia/rv&quot; style=&quot;宽度：220px；高度：110px；&quot; />;&lt;br />;转储一个从 0x80000000 开始的二进制文件，它可以由 rv 直接加载，如上例所示：不使用任何大于 32 位的整数类型，即使是乘法，因为它是用C89写的。以不完全符合 C89/99 的方式假定整数类型的宽度。很快就会修复这个问题，我正在研究一个防水的 &lt;stdint.h>;;对于 C89。 &lt;a href=&quot;https://hackernews.betacat.io/#show-hn-risc-v-core-written-in-600-lines-of-c89&quot; target=&quot;_blank&quot;>;[摘要]&lt;/a >; &lt;a href=&quot;https://news.ycombinator.com/item?id=36270150&quot; target=&quot;_blank&quot;>;[评论]&lt;/a>;&lt;/content>; &lt;/entry>; &lt;entry xml:base=&quot; https://hackernews.betacat.io/feed.xml&quot;>; &lt;title type=&quot;text&quot;>;OBS 合并 WebRTC 支持&lt;/stitle>; &lt;id>;https://github.com/obsproject/obs-studio/commit/ 851a8c216e14617fb523951839f3bdb240e85141&lt;/id>; &lt;更新>;2023-06-10T19:01:31.037261Z&lt;/更新>; &lt;link href=&quot;https://github.com/obsproject/obs-studio/commit/851a8c216e14617f b523951839f3bdb240e85141&quot;/>; &lt;作者>; &lt;name>;肖恩德尔&lt;/name>; &lt;uri>;https://news.ycombinator.com/user?id=肖恩德尔&lt;/uri>; &lt;/author>; &lt;content type=&quot;html&quot;>;&lt;img src= “https://opengraph.githubassets.com/541be099d92adbe96225ecd678fd2a003a3e2f8a468e8d20b76398880e805195/obsproject/obs-studio/commit/851a8c216e14617fb523951839f3bdb240 e85141&quot; style=&quot;宽度：220px；高度：110px；&quot; />;&lt;br />;这增加了一个 WHIP 输出 &amp;amp;amp;相关服务。 - 来自 DDRBoxman 的代码灵感 - 由 Sean DuBois &amp;amp;amp; 实施tt2468 - pkv 的各种修复和贡献。合着：tt24... &lt;a href=&quot;https://hackernews.betacat.io/#obs-merges-webrtc-support&quot; target=&quot;_blank&quot;>;[summary]&lt;/a>; &lt;a href =&quot;https://news.ycombinator.com/item?id=36273075&quot; target=&quot;_blank&quot;>;[评论]&lt;/a>;&lt;/content>; &lt;/entry>; &lt;entry xml:base=&quot;https:// hackernews.betacat.io/feed.xml&quot;>; &lt;title type=&quot;text&quot;>;Ted Kaczynski 去世了&lt;/stitle>; &lt;id>;https://www.nytimes.com/2023/06/10/us/ted- kaczynski-dead.html&lt;/id>; &lt;更新>;2023-06-10T18:01:31.037620Z&lt;/更新>; &lt;link href=&quot;https://www.nytimes.com/2023/06/10/us/ted -kaczynski-dead.html&quot;/>; &lt;author>; &lt;name>;mfiguiere&lt;/name>; &lt;uri>;https://news.ycombinator.com/user?id=mfiguiere&lt;/uri>; &lt;/author>; &lt;content type= &quot;html&quot;>;&lt;img src=&quot;https://static01.nyt.com/images/2023/06/11/obituaries/00Kaczynski/00Kaczynski-articleLarge.jpg?quality=75&amp;auto=webp&amp;disable=upscale&quot; style=&quot;width: 220 像素；高度：155 像素；&quot; />;&lt;br />;Theodore J. Kaczynski，被称为 Unabomber，在北卡罗来纳州的联邦监狱医疗中心去世，享年 81 岁。卡钦斯基对 1978 年至 1995 年的暴力爆炸事件负责，造成 3 人死亡、23 人受伤，其目的是煽动现代社会秩序的崩溃。 &lt;a href=&quot;https://hackernews.betacat.io/#ted-kaczynski-has-died&quot; target=&quot;_blank&quot;>;[摘要]&lt;/a>; &lt;a href=&quot;https://news.ycombinator。 com/item?id=36272409&quot; target=&quot;_blank&quot;>;[评论]&lt;/a>;&lt;/content>; &lt;/entry>; &lt;entry xml:base=&quot;https://hackernews.betacat.io/feed.xml&quot; >; &lt;title type=&quot;text&quot;>;问 HN：关于开设 YouTube 频道的建议？&lt;/stitle>; &lt;id>;https://news.ycombinator.com/item?id=36253565&lt;/id>; &lt;updated>;2023- 06-10T17:01:31.037971Z&lt;/updated>; &lt;link href=&quot;https://news.ycombinator.com/item?id=36253565&quot;/>; &lt;author>; &lt;name>;mr_o47&lt;/name>; &lt;uri>;https ://news.ycombinator.com/user?id=mr_o47&lt;/uri>; &lt;/author>; &lt;content type=&quot;html&quot;>;这篇文章提供了关于开始一个成功的 YouTube 频道的建议，包括坚持时间表的重要性，仔细选择利基市场，避免过度使用短裤。作者用倦怠和多样化的内容分享了自己的经历。 &lt;a href=&quot;https://hackernews.betacat.io/#ask-hn-advice-on-starting-a-youtube-channel&quot; target=&quot;_blank&quot;>;[摘要]&lt;/a>; &lt;a href=&quot; https://news.ycombinator.com/item?id=36253565&quot; target=&quot;_blank&quot;>;[评论]&lt;/a>;&lt;/content>; &lt;/entry>; &lt;entry xml:base=&quot;https://hackernews. betacat.io/feed.xml&quot;>; &lt;title type=&quot;text&quot;>;Merklizing key/value store for fun and profit&lt;/stitle>; &lt;id>;https://joelgustafson.com/posts/2023-05-04/ merklizing-the-key-value-store-for-fun-and-profit&lt;/id>; &lt;updated>;2023-06-11T03:01:31.038313Z&lt;/updated>; &lt;link href=&quot;https://joelgustafson.com /posts/2023-05-04/merklizing-the-key-value-store-for-fun-and-profit&quot;/>; &lt;author>; &lt;name>;joelg&lt;/name>; &lt;uri>;https://news.ycombinator .com/user?id=joelg&lt;/uri>; &lt;/author>; &lt;content type=&quot;html&quot;>;&lt;img src=&quot;https://joelgustafson.com/posts/2023-05-04/Component%2017.png &quot; style=&quot;宽度：220px；高度：80px；&quot; />;&lt;br />;假设你我都有一个本地键/值存储。我们怀疑我们的键/值存储的内容大部分相同，但可能存在一些差异：一些你有但我没有的条目，我有但你没有，或者同一个键的值冲突.我们比较数据库内容并识别差异的最佳方式是什么？天真地，我可以把我所有的参赛作品发给你，你也可以把你所有的参赛作品发给我。或者我可以将我的所有条目发送给您，您可以对它们进行迭代，然后将差异发回给我。但这在条目数量上仍然是线性的。如果你和我都非常关心如何使 diffs 高效，我们都可以维护一种特殊的 merkle 树，称为 Prolly 树，它允许我们跳过大部分共享条目并在对数时间内识别冲突。这种“merkle 同步”功能是一种强大且通用的点对点原语，可用作 CRDT 系统的天然持久层，“键/值存储的 rsync”，可变多写入器去中心化数据库的基础， 以及更多。 Prolly Trees 和它们的同类 Merkle Search Trees 是新思想，但已经被 ATProto / BlueSky、Dolt 和其他人使用。有一些关键差异使得这里的方法特别容易实现为现有键/值存储的包装器。我们将简要概述 merkle 树的一般情况，介绍 merkliized 键/值存储的设计，查看一些示例应用程序，介绍两个参考实现，并与其他项目进行比较。如果您已经是 merkle 树大师，并且使用它们来有效地区分键/值存储的前景对您来说似乎很自然，请随时跳过本节。 Merkle 树比听起来简单。它只是描述了一棵树，其节点已用哈希标记。叶子具有它们“值”的散列值（无论这对特定树意味着什么），并且每个父节点都具有其子节点的散列值。这意味着 merkle 树必须从叶子向上构建，因为每一层的哈希值都取决于下面层的哈希值。就是这样！ Merklizing 一棵树只是添加这些递归节点哈希，并在叶子发生变化时使它们保持最新。 merkliizing 的目标通常与根哈希唯一标识整棵树的事实有关——如果叶子的任何值发生变化，叶子的哈希也会发生变化，这将导致其父哈希发生变化，等等，一直到根。如果两棵 merkle 树具有相同的根哈希，您可以肯定地知道它们在整个树中都具有值。让我们看一下 merkle 树的两个突出应用：内容寻址文件系统和承诺方案。 IPFS 使用默克尔树来表示文件和目录。 IPFS 标识符是 PBNode Protobuf 结构的哈希值，如下所示。在最简单的情况下，文件表示为节点，原始文件为数据，没有链接，目录表示为没有数据的节点，每个子文件或子目录都有一个命名链接。由于目录由其条目的序列化列表的哈希值标识，并且每个序列化条目都有自己的哈希值，因此我们得到一个系统，其中任意大的目录树都可以用单个常量大小的哈希值唯一标识。这些散列允许 IPFS 进行“自我验证”：用户通过散列请求内容，并且可以自己简单地散列返回的字节以确保他们收到了他们期望的内容。我们免费获得的另一个属性是自动重复数据删除。当你要求 IPFS CLI 下载一个目录时，它必须一步一步地做，首先解析根节点，然后解析到它的子节点的链接，然后是它们的子节点，等等。在内部，IPFS 通过哈希将 merkle 节点存储在您的 ~/.ipfs 目录中的键/值存储中，并且在该迭代解析过程的每一步中，它都会首先检查本地数据库以查看它是否已经拥有它想要的节点。因此，如果您发布两个大目录，它们大部分相同，只有一些差异，例如容器镜像的连续版本，那么已经下载了一个的人只需下载实际更改过的文件，再加上容器镜像中的目录根的路径。默克尔树出现的另一个地方是承诺计划。假设您是一名摇滚明星，并且您有一份您希望在音乐会后台允许的密友名单。你可以把整个名单给保安人员，但你很受欢迎，有很多亲密的朋友，他们中的任何一个都可能出现，保安不想处理这么大的名单并做一个 O(n ) 每次有人要求进入时都会进行表扫描。因此，您可以使用朋友的名字（或公钥或其他）作为叶子来构建二叉默克尔树。每个朋友都被散列，每对叶散列被散列成一个二级散列，每一对二级散列被散列成一个三级散列，依此类推，直到只剩下一个根散列。如果在任何级别的末尾都剩下一个单独的节点，那很好，它会自行散列。怎么办？您将根哈希交给安全部门，并通过电子邮件向您的每个朋友发送他们自己从叶子到根的唯一节点路径。路径中的每个节点都包含路径中前一个节点的散列和前一个节点的邻居的散列（如果存在）。当你的朋友想要进入时，他们会向安全展示他们的 merkle 路径。安全性重新散列路径中的每个节点，从叶子开始；检查它是否是下一个节点中包含的哈希之一；并验证路径以您预先提供的相同根哈希结尾。你的朋友使用他们的 merkle 路径来证明包含在一个由单个恒定大小的散列唯一标识的集合中，并且它只需要 O(log(n)) 散列而不是 O(n) 表扫描。您为什么不直接将整个列表交给安全人员并要求他们在其上建立索引？为什么不使用数据库？一个原因可能是因为安全性完全在像以太坊这样的区块链上运行（不要问我这在类比中意味着什么）并且用它们存储数据非常昂贵。默克尔树让您可以将需要提交的数据压缩到一个固定大小的散列中。权衡是你的朋友必须记住他们的 merkle 路径。确实感觉 merkle 树可以帮助我们同步我们的键/值存储。我们看到了 IPFS 如何自动删除重复文件的基本操作原理的提示；在这里，我们的目标是删除键/值条目的共享子集。唯一的区别是文件系统已经有一个树结构，但是键/值接口只是一个逻辑上平面的条目数组。这种简单性是它们如此受欢迎的部分原因。尽管用户通常最终会滚动他们自己模糊的分层密钥格式，但灵活性和一致性能的承诺使他们很容易推理。为了默克化我们的键/值条目，我们必须建立我们自己的树结构。这听起来不像是个问题——毕竟，这是我们必须为承诺计划做的事情。我们每个人构建一个简单的二叉默克尔树。为此，我们首先需要就编码 e: (key: []byte, value: []byte) =>; []byte 将每个键/值对转换为可以散列的叶值。将键和值作为叶子的一部分进行散列很重要，但具体格式并不重要，只要它是内射的并且每个人都以相同的方式进行。我们按键按字典顺序对条目进行排序，对条目进行编码以获取叶子的值，并构建一个二叉树，将每个节点标记为其子哈希的哈希。请记住，我们的目标是枚举差异。您可能会猜到这种方法。我们从交换根哈希开始——如果它们匹配，那就太好了！我们确信我们拥有完全相同的树。如果他们不这样做，那么我们交换根的孩子的哈希值。我们递归到哈希值不匹配的子树，并跳过哈希值匹配的子树。在例子中，我们发现y0 != y0&amp;#39;，所以你发x0和x1，我发你x0&amp;#39;和 x1&#39;。然后我们查看那些并发现 x0 == x0&amp;#39;但是 x1 != x1&amp;#39;，所以你只需将 c:baz 和 d:qux 发送给我，我将 c:eee 和 d:qux 发送给你。这看起来很复杂，但这个过程与树的大小成对数缩放，这非常漂亮。当然，这只是在单个条目发生冲突的情况下。如果足够多的条目发生冲突，则无论如何都无法发送整个树。唯一的区别是我在树的开头插入了一个新条目 A:AAA（大写字母排在小写字母之前）。但是因为我们从头开始将节点配对在一起，所以新条目会偏移整个树的其余部分，根本没有给我们匹配的哈希值。以这种方式构建二叉树很脆弱，使用任何大小的固定大小的块也是如此。即使我们有很多公共条目，它们也不会导致匹配更高级别的哈希值，除非它们恰好在块边界上对齐。另外，它不能增量维护。当插入新条目或删除旧条目时，您必须丢弃整棵树并从头开始重新构建它。这是不幸的，因为固定大小的分块具有一些我们希望从树构建算法中获得的其他重要特性：它很简单，它总是产生平衡的树，它可以与任何块大小一起使用，并且它是确定性的。决定论是至关重要的。请记住，我们的目标是通过将键/值条目转换为共享的高级默克尔树节点来识别和跳过键/值条目的共享子集，因为它们可以通过哈希进行比较。如果我们的 merkle 树的结构取决于条目的插入顺序，或者不是叶子内容的纯函数，那么我们就失去了识别和跳过那些共享的条目子集的机会。固定大小分块的脆弱性也是文件共享系统中出现的一个问题。默认情况下，IPFS 将大文件拆分为 262144 字节的块以启用 torrent 风格的并发下载（这就是 PBNode 结构并不总是与文件和目录一对一映射的原因）。这意味着如果在接近开头的地方编辑文件，那么所有大文件的块都会更改。我们有点把球门柱移到这里，但如果它们也可以在一个大文件的两个版本中删除重复块不是很好吗？对我们来说幸运的是，已经有众所周知的技术可以减轻文件中的偏移敏感性（IPFS 支持多个 --chunker 选项）。最简单的是使用滚动哈希函数来导出内容定义的块边界。滚动哈希函数对流中字节的移动窗口进行哈希处理，有效地仅对每个字节的最后 n 个字节进行哈希处理。您可以使用 this 通过在其散列以一定数量的前导二进制零开头的每个字节开始一个新块来对文件进行分块。由于散列是窗口的纯函数，字节流将以相同的方式分块，而不管它出现在文件的哪个位置。您可以将阈值设置为零的长前缀以获得通常较大的块，或将阈值设置为短前缀以获得通常较小的块。在实践中，通常添加最小和最大大小，或其他变体来控制块大小的分布。这种技术甚至早于网络； rsync（文件同步工具和 Dropbox 杀手）从 1996 年就开始这样做了！ （说到 rsync，难道我们不能只是 rsync 数据库映像吗？好吧......是的。rsync 可以让你从单一真实来源服务器进行高效复制，如果这就是你想要的，你不需要merkle 树。但是你可以用 merklized 键/值存储做更多的事情，而不仅仅是复制。我们稍后会详细介绍。）要将这个想法应用到我们的 merkle 树，我们甚至不需要滚动哈希函数，因为我们不使用字节流。我们可以简单地使用节点本身的哈希值来确定性地将它们分成兄弟组，这将创建一个结构对插入和删除具有鲁棒性的树。现在，我们只考虑从头开始构建树，稍后再考虑增量维护。 Let&#39;s say we want the nodes of our merkle tree to have Q children on average. The intuition is to divide up the space of possible hashes into Q evenly-sized buckets, and have the one-in-Q nodes that fall into the first bucket mark boundaries between parents. Here&#39;s the rule: A node is the first child of its parent if u32(node.hash[0..4]) &amp;lt; (2^32 / Q). We call these nodes boundary nodes. A boundary node is the first child of a new parent, and a non-boundary nodes are siblings of the previous boundary node.就是这样！ This totally determines the structure of the tree. You can imagine scanning across a layer, testing each node&#39;s boundary status, creating a new parent on the next level if it&#39;s a boundary node, or adding it as a child of the previous parent if not. Once we finish creating parents for a level, we calculate their hashes by hashing the hashes of all their children in order, and repeat the whole process level after level until there&#39;s just one root node left. There&#39;s just one more twist: we add a special anchor node at the beginning of every level, which is always the first child of its parent, which is also always an anchor node. This gives a stable backbone to the tree - it will make our lives easier when we get to incremental maintenance, and means that even the empty key/value store has a well-defined root node (the leaf-level anchor node). The leaf-level anchor node&#39;s hash is the hash of the empty input h(). With all this in mind, let&#39;s draw out a larger example tree. The boundary nodes (with hashes below the 2^32/Q threshold) have bold/double borders. Each node is labelled with the key of their first leaf-level entry. This makes it easy to address any node by (level, key), with level = 0 for the leaves and key = null for the anchor nodes. Arranged rectangularly, with first sibling/next sibling arrows instead of parent-child arrows, the whole thing looks more like a skip list than a tree: If this is confusing, consider the node (0, &amp;#34;c&amp;#34;), which represents a key/value entry c -&amp;gt; baz. Its hash h(e(&amp;#34;c&amp;#34;, &amp;#34;baz&amp;#34;)) was less than the 2^32/Q threshold, so it&#39;s a boundary node and gets “promoted” to (1, &amp;#34;c&amp;#34;). But the hash there h(h(e(&amp;#34;c&amp;#34;, &amp;#34;baz&amp;#34;)), h(e(&amp;#34;d&amp;#34;, ...)), h(e(&amp;#34;e&amp;#34;, ...)), h(e(&amp;#34;f&amp;#34;, ...))) isn&#39;t less than the threshold, so (1, &amp;#34;c&amp;#34;) doesn&#39;t create a (2, &amp;#34;c&amp;#34;) parent. Instead, it&#39;s a child of the previous node at level 2, which in this case is the anchor (2, null). This way of building a merkle tree is clearly deterministic, but how does it behave across changes? Is it really less brittle than fixed-size chunks? How much of the tree is affected by a random edit? Can we find limits? Let&#39;s start with some visualizations to build our intuition. Here, we build a tree with Q = 4 (so nodes whose hash begins with a byte less than 0x40 are boundaries) by inserting entries at the start, at the end, and randomly, respectively. The nodes that are created or whose hash changed in each step are highlighted in yellow, the rest existed with the same hash in the previous frame.很酷！ In all cases, even random, almost all of the higher-level nodes survive edits, and changes are localized to the new entry&#39;s direct path to the root... plus a few in the surrounding area. Here&#39;s a longer look at in-place edits in the tree (setting random new values for existing keys): The tree&#39;s height goes up and down over time, but tends to stay around level 4, or a little below. We&#39;re using Q = 4 with 64 entries, but log_4(64) = 3. There&#39;s a slight bias in the height due to the way we&#39;ve defined anchor nodes - it&#39;s like scaffolding that a regular tree doesn&#39;t have, and effectively adds 1 to the average height. Another thing to notice is that the nodes in the direct path from the updated leaf to the root always change, but a few other nodes change as well. These other nodes are always above/before the direct path to the root, never below/after. There&#39;s not a clear limit to how many of these siblings can be affected - at each level, zero and one seem to be the most common numbers, but if you watch carefully you can find frames where three consecutive nodes on one level all change. Here&#39;s an example from frame 44. What&#39;s up with that? Why are the changes propagating backward? How far can it go, and how far does it go on average? Let&#39;s pivot back to theory and consider the inductive case of updating the hash of a node at (l, k) from H to H&amp;#39;. The node either was or was not a boundary node before, and it either is or is not a boundary node after, giving us two boring cases and two interesting cases: The node was non-boundary node and remains a non-boundary node. The node was in the middle or at the end of its parent, stays there, and doesn&#39;t affect its siblings. Its parent&#39;s hash changes but the tree structure doesn&#39;t. The node wasn&#39;t a boundary node before, but becomes a boundary node after the update. It splits its parent, creating (l+1, k) with (l, k) and the rest of its siblings as children. The old parent&#39;s hash changes, and there&#39;s also a new node at the parent level. This doesn&#39;t affect later parents (l+1, j), j &amp;gt; k if they exist, or any of their children. The node was a boundary node before, but is no longer a boundary node after. This means there was a (l+1, k) node, but we delete it and all (l+2, k), (l+3, k) etc. if they exist. All children of (l+1, k) get merged into the previous parent at level l+1, whose hash changes. The node was a boundary node before, and remains a boundary node after. (l+1, k) survives, but its hash changes. Notice how cool it is that we&#39;ve recovered “splitting” and “merging” - familiar operations in balancing traditional mutable trees - from analyzing our deterministic bottom-up tree building algorithm! We wouldn&#39;t necessarily expect an arbitrary such algorithm to give rise to persistent node identity at all. The extra nodes we see changing at each level are artifacts of splits, and the large triangular wake in frame 44 is an artifact of repeated splits. Here&#39;s frame 43 and 44 side-by-side. The update to the entry at key 0x0030 caused its parent split, which also caused its grandparent to split. Splits can propagate backwards, but only happen with probability 1/Q. Quantifying the exact number of expected splits caused by a change is... hard. In a tree with n leaf entries, we expect a path of log_Q(n)+1 nodes from the leaf to the root, of which 1 in Q are boundaries and the other Q-1 in Q aren&#39;t. A split happens when a non-boundary node becomes a boundary, and has conditional probability 1/Q, so we expect at least (log_Q(n)+1) * ((Q-1)/Q) * (1/Q). Splits create new parents that might themselves induce further splits, so the real number is a little more, but we also run out of space when we hit the anchor edge of the tree, so propagation is bounded by that as well. In the end, it&#39;s something on the order of (log_Q(n)+1)/Q. This still isn&#39;t a complete description of the changes to the tree since we haven&#39;t mentioned merging and the nodes that get deleted during the process. But because we know the tree is pseudo-random and therefore self-balancing, we can infer that on average it must delete the same number of nodes it creates. There&#39;s a funny kind of symmetry here: only changes to boundary nodes can cause merges, and they&#39;re very likely (1-1/Q) to do so, while only changes to non-boundary nodes can cause splits, and they&#39;re not very likely (1/Q) to do so. But because boundary nodes themselves account for just 1/Q of the nodes overall, it all evens out! I find it easiest to characterize the process intuitively as “towers are slow to grow and quick to fall”. This is where embracing the skip-list perspective is especially helpful. Nodes at high levels are towers of hashes that all happen to be less than 2^32/Q; every time the hash at the top of a tower changes, it has a small 1/Q chance of growing to the next level (and, if it does, another 1/Q of growing to the level after that, and so on). On the other hand, every time a hash at a lower level of a tower changes, it has a large 1-1/Q chance of pruning the tower right then and there. And even if it happens to survive, it has another 1-1/Q of getting pruned at the next level, and so on. Let&#39;s try it out empirically! Here&#39;s the output of a test that creates a tree (Q = 4 again) with 65,536 entries - one for every key from 0x0000 to 0xffff - and then updates a random entry with a random value 1000 times, recording for each change the height of the tree, total node count, leaf node count, average degree, and number of nodes created, updated, and deleted. Cool! We have an average degree of Q = 4. We expect our total node count to be 65536 + 65536/4 + 65536/4^2 + ... = 65536 * 4/3 = 87381, and it&#39;s pretty close. Here, height is reported as root.level + 1, and we see the same extra unit from the anchor tower scaffolding than the log_4(65536) + 1 = 9 we&#39;d naively expect. The important parts are the created and deleted numbers. These quantify how robust the tree really is to edits. On average, we update all 10 nodes in the direct path to the root, and additionally create another ~2.28 and delete another ~2.25 along the way. And guess what! (log_4(65536)+1) * (1/4) is exactly 2.25. But 65,536 entries is still small for a database, and Q = 4 is a toy setting. After all, we only really care about any of this if we&#39;re on a scale where sharing the full state is completely intractable. Let&#39;s try Q = 32 with 2^24 = 16,777,216 entries, where we should expect around (log_32(16777216)+1) * (1/32) = 0.18125 splits and merges per change. NICE. Making a random change in our key/value store with 16 million entries only requires changing a little less than 7 merkle tree nodes on average. One final property to highlight: we know for sure that changes within a subtree can never affect the subtrees to its right. Here&amp;#39;s the example tree again: No amount of inserting, updating, or deleting entries before g:... will change the way the entries g:... through m:... organize into the subtree under (3, &amp;#34;g&amp;#34;). This is not a trivial property! It&#39;s only true because our boundary condition is stateless; each node determines its own boundary status independently of its siblings. In particular, if we had used a rolling hash over a window of nodes for determining boundaries at each level, this wouldn&#39;t hold. All that we have so far is a logical description of a tree structure, and a vague promise that augmenting the logically flat key/value interface with this fancy merkle tree will unlock some interesting syncing capabilities. But how are we actually implementing this? Key/value stores are typically just B-trees, designed around real-world platform constraints. If we take the task of “merklizing the key/value store” literally and try to pack our tree directly into pages on-disk, we quickly find that there&#39;s inherent conflict between practical B-tree design and the deterministic pseudo-random structure we derived. For example, even though we can set Q to control the average fanout degree, there&#39;s no hard upper limit on how many children a node might end up with, but a basic principle of B-trees is to work strictly inside 4096-byte pages. Maybe we could go back and revise our structure, but then we&#39;re playing a game of tradeoffs, making an already-complicated B-tree even more complicated. We take an existing key/value store and project the tree structure onto it. This means there are two “key/value stores” in play - an external merklized one, and an internal one used to implement the merkle tree. Every merkle tree node is represented as an internal key/value entry with key [level, ...key] and a value [...hash, ...value?]. Specifically: the rest of of the internal key key[1..] is the (external) key of the node&#39;s first leaf entry leaf nodes store their external value after the hash, in the remaining bytes value[K..] of the internal value The most interesting aspect of this mapping is that no parent-to-child or sibling-to-sibling links have to be explicitly represented, since those traversals can be done using the underlying key/value store with the information already present in each node. Given a parent (l, k), we know its first child has internal key [l-1, ...k]. How about sibling iteration?简单的！ We iterate over internal entries, breaking when the next internal key has the wrong level byte or when the next entry&#39;s hash (internal value[0..K]) is less than 2^32/Q, since that means it&#39;s the first child of the next parent. Another serendipitous benefit of content-defined chunking! Decoupling the two trees lets them each do what they do best. Internally, the underlying key/value store can pack whichever entries into whichever pages it wants, with no regard for the merkle-level node boundaries, keeping empty slots for future insertions, and so on. Every update, split, and merge translates directly to a single set or delete of an internal key/value entry. This does mean that the overall asymptotic complexity gets bumped up a logarithmic notch, since every external operation translates into log_Q(n) internal operations. Implementing the external set/delete operations involves setting or deleting the corresponding leaf node and then propagating up the levels, splitting, merging, or updating the intermediate nodes as needed. There are a few tricky edge cases that make this non-trivial, but our TypeScript and Zig reference implementations are both able to do it in ~500 careful lines of code. So far, we&#39;ve been vague about how these merkle skip lists are useful, casually talking about “syncing” without saying what exactly that means. We&#39;ll use TypeScript to make things concrete. First, some types for keys and nodes. Syncing will still be directional, where the initiator plays the role of a local client making a series of requests, and the other party plays the role of a remote server responding to those requests. But, to emphasize that the same parties could play either role, we&#39;ll call the server/remote role Source and the client/local role Target. To be a server, you just need to expose the Source interface methods over an HTTP API, WebSocket connection, or libp2p protocol, etc. Locally, all we need from the Target tree is the same methods as Source, plus the ability to iterate over a bounded range of merkle nodes at a given level. We&#39;ll also throw the key/value interface methods into there, even though they&#39;re not used by the syncing process itself. It&#39;s crucial that this iterator doesn&#39;t break between “parent boundaries” - it&#39;s another place where it&#39;s more appropriate to think of the structure as a skip-list than a tree. In the big example skip-list diagram, nodes(1, { key: &amp;#34;c&amp;#34;, inclusive: true }, null) must yield the level-1 nodes with keys c, g, i, and m, even though g was the first child of a different parent. Cool! Now for the main attraction. Everything that we&#39;ve done so far was all building up to this one function sync. sync uses the methods in the Source and Target interfaces to yield Delta objects for every key-wise difference between the source and target leaf entries. This format generalizes the three kinds of differences there can be between key/value stores: sourceValue !== null &amp;amp;&amp;amp; targetValue === null means the source tree has an entry for key but the target tree doesn&#39;t. sourceValue === null &amp;amp;&amp;amp; targetValue !== null means the target tree has an entry for key but the source tree doesn&#39;t. sourceValue !== null &amp;amp;&amp;amp; targetValue !== null means the source and target trees have conflicting values for key. sourceValue and targetValue are never both null, and they&#39;re never both the same Uint8Array value. The actual implementation of sync is a depth-first traversal of source that skips common subtrees when it finds them, plus some careful handling of a cursor in the target tree&#39;s range. You can see it in ~200 lines of TypeScript here. It turns out that this this low-level Delta iterator is an incredibly versatile primitive, with at least three distinct usage patterns. Suppose we want to recreate rsync, where Alice is the source of truth and Bob just wants to keep a mirror up-to-date. Bob has his own local tree target and a client connection source to Alice; whenever he wants to update, he initiates a sync and adopts Alice&#39;s version of each delta.就这么简单！ And maybe Bob has other side effects to await for each delta, or additional validation of the values, or whatever.伟大的！ He can do whatever he wants inside the for await loop body; the sync iterator just yields the deltas. Suppose instead that Alice and Bob are two peers on a mesh network, and they&#39;re both subscribed to the same decentralized PubSub topic, listening for some application-specific events. Bob goes offline for a couple hours, as is his wont, and when he comes back he wants to know what he missed. In this case, they can both store events in our merklized key/value store using the hash of a canonical serialization of each event as the key. Then when Bob wants to check for missing messages, he initiates a sync with Alice, only paying attention to the entries that Alice has that he doesn&#39;t, and expecting that there won&#39;t be any value conflicts, since keys are hashes of values. It&#39;s just a minor variation of the last example, but this time it&#39;s not something rsync could help us with. Bob doesn&#39;t want to lose the events the he has that Alice doesn&#39;t, and rsync would overwrite them all. Bob wants to end up with the union of his and Alice&amp;#39;s events, so he needs to use our async delta iterator. And when he&amp;#39;s done, Alice can flip it around and initiate the same kind of sync with Bob to check for events she might have missed! Today, one standard approach to this problem is to use version vectors (not to be confused with vector clocks), but that requires events to have a user ID, requires each user to persist their own version number, and produces vectors linear in the total number of users to ever participate. In many systems, this is fine and even natural, but it can be awkward in others that have lots of transient users or are supposed to be anonymous. Why couple retrieval with attribution if you don&#39;t have to? Merkle sync lets us achieve the same thing while treating the events themselves as completely opaque blobs. (And what if retrieving a specific event fails? If Eve skips a version number, does Bob keep asking people for it until the end of time?) It&#39;s cool that merkle sync can implement grow-only sets and single-source-of-truth replication, and they&#39;re real-world use cases, but neither are “peer-to-peer databases” in a true sense. What if we want multi-writer and mutability? Merkle sync doesn&#39;t magically get us all the way there, but it brings us close. You can use it to merge concurrent versions of two databases, but you need your own way to resolve conflicts between values. As you might expect, the merge function must be commutative, associative, and idempotent in order to be well-behaved. associativity: merge(k, a, merge(k, b, c)) == merge(k, merge(k, a, b), c) for all k, a, b, and c idempotence: merge(k, a, a) == a for all k and a (although this is more of a conceptual requirement since merge will never be invoked with identical values) To get multi-writer mutability, Alice and Bob wrap their values with some tag that lets them compute a deterministic causal ordering. Here&#39;s a naive implementation of merge that uses last-write-wins timestamps. Now, when Alice and Bob sync with each other, they end up with the most recent values for every entry. If they want to “delete” entries, they have to settle for leaving tombstone values in the key/value store that are interpreted as deleted by the application, but this is common in distributed systems. Also note that merge doesn&#39;t have to return one of sourceValue or targetValue - for some applications there could be a merge function that actually combines them in some way, as long as it&#39;s still commutative and associative - but arbitrating between the two is probably the most common case. What we&#39;ve essentially implemented is a toy state-based CRDT, which is a whole field of its own. Similar to the grow-only set example, the utility of merkle sync here is not that it provides a magic solution to causality, but rather that it enables a cleaner separation of concerns between layers of a distributed system. Alice and Bob can use whatever approach to merging values that makes sense for their application without worrying about the reliability of decentralized PubSub delivery or having to track version vectors for retrieval. You might be worried about operating on the target tree mid-sync. Operations can cause splits and merges at any level - will this interfere with the ongoing depth-first traversal? Fortunately, this is actually fine, specifically due to the property that mutations in any subtree never affect the subtrees to their right. The target tree can always safely create, update, or delete entries for the current delta&#39;s key. Unfortunately, the same can&#39;t be said for the source tree. The source needs to present a stable snapshot to the target throughout the course of a single sync, since the intermediate nodes are liable to disappear after any mutation. This means syncing needs to happen inside of some kind of explicit session so that the source can acquire and release the appropriate locks or open and close a read-only snapshot. The animations and tests we saw in previous sections were run on a reference implementation called Okra. Okra is written in Zig, using LMDB as the underlying key/value store. Its basic data structures are Tree, Transaction, and Cursor. Internally, all three are generic structs parametrized by two comptime values K: u8 and Q: u32; K is the size in bytes of the internal Blake3 hashes. These have default values K = 16 and Q = 32, but anyone could import the generic types and instantiate them with different settings. Okra can be used as a compiled library, directly by another Zig project via git submodules (internal structs documented here), or via the first-party native NodeJS bindings. The NodeJS bindings are simple wrappers that expose Tree, Transaction, and Cursor as JS classes. You can build these yourself with cd node-api &amp;amp;&amp;amp; make, which assumes /usr/local/include/node exists. Alternatively, precompiled bindings are published on NPM as @canvas-js/okra-node and should work on all x64/arm64 MacOS/linux-glibc/linux-musl platforms. The NodeJS classes are documented in okra/node-api/README.md. Okra also has a CLI, which can be built with zig build after installing Zig and fetching the submodules. The CLI is most useful for visualizing the state of the merkle tree, but can also be used for getting, setting, and deleting entries. As a wrapper around LMDB, Okra has fully ACID transactions with get(key), set(key, value), and delete(key) methods, plus a read-only iterator interface that you can use to move around the merkle tree and access hashes of the merkle nodes. Only one read-write transaction can be open at a time, but any number of read-only transactions can be opened at any time and held open for as long as necessary at the expense of temporarily increased size on-disk (LMDB is copy-on-write and will only re-use stale blocks after all transactions referencing them are closed). The Zig implementation does not implement sync, since syncing is async and so closely tied to choice of network transport. We also have a compatible implementation in pure TypeScript at canvasxyz/okra-js, which can be used with any backend satisfying an abstract KeyValueStore interface. The NPM packages @canvas-js/okra-idb and @canvas-js/okra-memory instantiate this with IndexedDB and an in-memory red/black tree, respectively. These implement sync with the same AsyncIterable&amp;lt;Delta&amp;gt; interface described here, but don&#39;t have transaction snapshots, so sources must acquire a lock during syncing for consistency. Improving the usability of these libraries is an ongoing project, so treat them as research prototypes for now. I&#39;ll step into the first person for a friendly conclusion. I started looking into merklized databases last summer in search of a reliable persistence layer to complement libp2p&#39;s GossipSub, and found that variants of deterministic pseudo-random merkle trees were an active early research area. I was ecstatic. The original paper on Merkle Search Trees (MSTs) describes something very different than the approach I ended up pursuing. MSTs are more like classical B-Trees where the intermediate nodes store values too: each key/value entry&#39;s hash determines its level in the tree, and nodes interleave values with pointers to nodes at the level below. It&#39;s actually quite complicated. Prolly Tree seems to be the consensus name for the bottom-up/dynamic chunking approach. I first saw the idea described in this blog post, but it appears to have originated in the now-dead project attic-labs/noms. Dolt, a relational database with git-like characteristics, has a great blog post about Prolly Trees that spends a lot of time focusing on ways to tune the chunk size distribution. Our naive u32(node.hash[0..4]) &amp;lt; 2^32/Q condition gives us parents with Q children on average, but in a geometric distribution with more smaller chunks than bigger chunks. Dolt took on the challenge of implementing a native Prolly Tree directly on-disk, so they reworked the chunk boundary condition to get chunks to fit more consistently into 4096-byte pages, transforming the distribution on the left into the distribution on the right. A simple solution is to use the size of the current chunk as an input into the chunking function. The intuition is simple: if the probability of chunk boundary increases with the size of the current chunk, we will reduce the occurrence of both very-small and very-large chunks. This was something I planned to do, but shelved as the prospect of working on top of existing key/value stores came into focus. As far as I can tell, Okra&#39;s generic key/value backend is a novel approach, and hinges on the specific way the fixed anchors give nodes stable (level, key) identifiers. Or maybe just rotating the tree 45 degrees, I can&amp;#39;t really tell. I don&#39;t know enough about either database internals or distributed systems to thoroughly compare the trade-offs between the Okra way and a full-fledged on-disk Prolly Tree. I&#39;m really happy with how easy Okra was to implement, especially in the browser context over a single IndexedDB object store, and personally place a high value on that kind of simplicity as long as it meets my needs. But I also know that lots of serious engineering went into Dolt and would bet it performs better at scale. Another major aspect of Dolt&#39;s implementation is that it has git-like time-travel. Like LMDB, Dolt is copy-on-write, but it keeps the old blocks around so that it can access any historical snapshot by root hash. One future direction that I&#39;m excited to explore is packaging Okra as a SQLite plugin. I think it could work as a custom index that you can add to any table to make it “syncable”, in any of the three replicate/union/merge usage patterns, with another instance of the table in anyone else&#39;s database. More generally, I find myself constantly impressed by the unreasonable utility of merklizing things. As always, the friction is around mutability and identity, but pushing through those headwinds seems to consistently deliver serendipitous benefits beyond the initial goals. We&#39;re used to thinking of “content-addressing” as an overly fancy way of saying “I hashed a file” (or at least I was), but I&#39;m coming around to seeing a much deeper design principle that we can integrate into the lowest levels of the stack. Overall it seems like there&amp;#39;s an emerging vision of a lower-level type of decentralization, where the data structures themselves sync directly with each other. The modern computer has hundreds of databases for various kinds of apps at all times - what if the application layer didn&#39;t have to mediate sync and replication logic at all? What if you could make a social app without writing a single line of networking code? Many thanks to Colin McDonnell, Ian Reynolds, Lily Jordan, Kevin Kwok, and Raymond Zhong for their help in editing. &lt;a href=&quot;https://hackernews.betacat.io/#merklizing-the-key-value-store-for-fun-and-profit&quot; target=&quot;_blank&quot;>;[summary]&lt;/a>;&lt;/content>; &lt;/entry>; &lt;entry xml:base=&quot;https://hackernews.betacat.io/feed.xml&quot;>; &lt;title type=&quot;text&quot;>;An incomplete history of London&#39;s television studios&lt;/stitle>; &lt;id>;https://www.tvstudiohistory.co.uk/&lt;/id>; &lt;updated>;2023-06-11T03:01:31.038664Z&lt;/updated>; &lt;link href=&quot;https://www.tvstudiohistory.co.uk/&quot;/>; &lt;author>; &lt;name>;timthorn&lt;/name>; &lt;uri>;https://news.ycombinator.com/user?id=timthorn&lt;/uri>; &lt;/author>; &lt;content type=&quot;html&quot;>;&lt;img src=&quot;https://www.tvstudiohistory.co.uk/wp-content/uploads/2021/06/Homepage_top_image-e1623009924952-768x851.jpg&quot; style=&quot;width: 220px; height: 244px;&quot; />;&lt;br />;Welcome to my website. I&#39;m a recently retired lighting director and over my long career I worked in most of London&#39;s TV studios – many of which sadly no longer exist. I have also lit shows in a number of studios around the rest of the country. Originally a BBC staffer, I went freelance in 2002 and began to ask a few colleagues with many years&#39; experience what they remembered of the good old times in the studios I was now working in. For my own benefit really, I started to explore further using the Internet and a number of out of print publications. In 2006 I created this website, which was updated with new software in 2021. Initially there were many omissions and plenty of errors but thanks to people contacting me, these have been gradually corrected over the years. I am still very much welcoming any comments and, of course, corrections and additions. About 350 people have contributed so far and I am greatly in their debt for taking the trouble to write or talk to me. In fact, I have received well over 2,500 messages in total – some with corrections or additional information, others simply saying thanks. If you send me any photos I will assume that you consent to them being published here. Please go to the &#39;bibliography and links&#39; page for a list of some of those who have provided information. This website is very large so don&#39;t expect to read it all in a single day! I have divided it into sections, within which the individual studios are listed. Feel free to dip in and out as the mood takes you – but do explore areas you know nothing about. You may be surprised at what you discover. And if you enjoy what you see – please tell other people about it. I&#39;ve written it for fun, not money, and hope that others find the information within it as fascinating as I did researching it. Please look at the Introduction page – it includes a summary of how the industry is currently provided with facilities and some important definitions – explaining for instance the difference between a studio and a stage. Backup Tech is a charity that supports technical professionals working in live events, theatre, television and film who through no fault of their own are unable to support themselves or their families due to accident or illness. If you have enjoyed reading this website, can I ask you to consider making a donation? Please visit www.backuptech.uk to find out how you can help. Even a few pounds will make a difference. Martin Kempton joined the BBC as a trainee camera assistant in 1976, based at Television Centre. He soon became a cameraman and after 9 years moved across to the lighting department. Following a few years as a racks operator, then console operator, he was promoted to lighting director in 1990. He left the BBC and went freelance in 2002. His CV spans comedy, entertainment and drama and he has lit many well-known shows. He has been shortlisted on 10 occasions for Knight of Illumination Awards, winning 3 times. He has also received 7 RTS Craft Award nominations, winning twice and is the proud owner of a Welsh Bafta. His IMDb page can be found here – Martin Kempton – IMDb A little word of warning to students: the written material on this site is copyright. You may not copy it and use it as your own work! Please – if you are wishing to use any written material for publication in a book, TV or radio programme or on-line, feel free to ask and I shall try to be as helpful as possible. Do not assume that any images are free to be copied or used elsewhere. Most have been sent to me with the intention of being used only on this website and I can&#39;t say it is OK to use them anywhere else. Some are personal photographs, others may have been copied from publications without my knowledge. Please don&#39;t write to me asking for permission to use the images. That permission is not mine to give. If you believe that you own the copyright to any image displayed here and wish it to be removed – or just perhaps given a credit if one is missing – I will of course be happy to oblige. Many of the illustrations are copyrighted by their respective copyright holders according to the original copyright or publication date as printed on the artwork or publication and are reproduced here simply for historical reference, educational and research purposes. Do contact me if you have any snippets of information to add. If you read something here you&#39;re sure isn&#39;t correct – PLEASE let me know! In my defence I would say that I have found many examples of contradictory information, dates etc but I have done my best to establish the most likely correct ones. I shall happily add your name to the list of credits – unless you wish to remain anonymous. &lt;a href=&quot;https://hackernews.betacat.io/#an-incomplete-history-of-londons-television-studios&quot; target=&quot;_blank&quot;>;[summary]&lt;/a>;&lt;/content>; &lt;/entry>; &lt;entry xml:base=&quot;https://hackernews.betacat.io/feed.xml&quot;>; &lt;title type=&quot;text&quot;>;DeArrow: Crowdsourcing better titles and thumbnails on YouTube&lt;/stitle>; &lt;id>;https://github.com/ajayyy/DeArrow&lt;/id>; &lt;updated>;2023-06-10T20:01:31.039011Z&lt;/updated>; &lt;link href=&quot;https://github.com/ajayyy/DeArrow&quot;/>; &lt;author>; &lt;name>;tech234a&lt;/name>; &lt;uri>;https://news.ycombinator.com/user?id=tech234a&lt;/uri>; &lt;/author>; &lt;content type=&quot;html&quot;>;&lt;img src=&quot;https://raw.githubusercontent.com/ajayyy/DeArrow/master/public/icons/logo-128.png&quot; style=&quot;width: 220px; height: 220px;&quot; />;&lt;br />;本文提供了有关如何使用 npm run build 命令生成 Chrome 或 Firefox 扩展的开发或生产版本的说明。构建的扩展可以作为 Chrome 中的解压扩展加载，也可以作为 Firefox 中的临时扩展加载。 &lt;a href=&quot;https://hackernews.betacat.io/#dearrow-crowdsourcing-better-titles-and-thumbnails-on-youtube&quot; target=&quot;_blank&quot;>;[summary]&lt;/a>; &lt;a href=&quot;https://news.ycombinator.com/item?id=36273890&quot; target=&quot;_blank&quot;>;[comments]&lt;/a>;&lt;/content>; &lt;/entry>; &lt;entry xml:base=&quot;https://hackernews.betacat.io/feed.xml&quot;>; &lt;title type=&quot;text&quot;>;What is Technicolor? (2021)&lt;/stitle>; &lt;id>;https://www.studiobinder.com/blog/what-is-technicolor-definition/&lt;/id>; &lt;updated>;2023-06-10T19:01:31.039371Z&lt;/updated>; &lt;link href=&quot;https://www.studiobinder.com/blog/what-is-technicolor-definition/&quot;/>; &lt;author>; &lt;name>;thunderbong&lt;/name>; &lt;uri>;https://news.ycombinator.com/user?id=thunderbong&lt;/uri>; &lt;/author>; &lt;content type=&quot;html&quot;>;&lt;img src=&quot;https://s.studiobinder.com/wp-content/uploads/2020/07/What-is-Technicolor-StudioBinder.jpg&quot; style=&quot;width: 220px; height: 124px;&quot; />;&lt;br />;Technicolor 是用于在电影中制作色彩的一系列流程，该公司在 1916 年至 1932 年期间对其系统进行了修补，以使好莱坞可以使用该流程。 Technicolor 电影以其明亮、大胆、饱和的色彩而闻名。 &lt;a href=&quot;https://hackernews.betacat.io/#what-is-technicolor-2021&quot; target=&quot;_blank&quot;>;[summary]&lt;/a>; &lt;a href=&quot;https://news.ycombinator.com/item?id=36254776&quot; target=&quot;_blank&quot;>;[comments]&lt;/a>;&lt;/content>; &lt;/entry>; &lt;entry xml:base=&quot;https://hackernews.betacat.io/feed.xml&quot;>; &lt;title type=&quot;text&quot;>;Do open source licences cover the Ship of Theseus?&lt;/stitle>; &lt;id>;https://shkspr.mobi/blog/2023/06/do-open-source-licences-cover-the-ship-of-theseus/&lt;/id>; &lt;updated>;2023-06-10T15:01:31.039721Z&lt;/updated>; &lt;link href=&quot;https://shkspr.mobi/blog/2023/06/do-open-source-licences-cover-the-ship-of-theseus/&quot;/>; &lt;author>; &lt;name>;edent&lt;/name>; &lt;uri>;https://news.ycombinator.com/user?id=edent&lt;/uri>; &lt;/author>; &lt;content type=&quot;html&quot;>;&lt;img src=&quot;https://shkspr.mobi/apple-touch-icon.png&quot; style=&quot;width: 220px; height: 221px;&quot; />;&lt;br />;作者下载了一个带有归属许可的HTML模板，但最终重写了75%的HTML和更改了61%的CSS。他们质疑是否仍需要根据许可条款注明原作者的身份。 &lt;a href=&quot;https://hackernews.betacat.io/#do-open-source-licences-cover-the-ship-of-theseus&quot; target=&quot;_blank&quot;>;[summary]&lt;/a>; &lt;a href=&quot;https://news.ycombinator.com/item?id=36256325&quot; target=&quot;_blank&quot;>;[comments]&lt;/a>;&lt;/content>; &lt;/entry>; &lt;entry xml:base=&quot;https://hackernews.betacat.io/feed.xml&quot;>; &lt;title type=&quot;text&quot;>;Play (1) Linux manual page&lt;/stitle>; &lt;id>;https://linux.die.net/man/1/play&lt;/id>; &lt;updated>;2023-06-11T01:01:31.040066Z&lt;/updated>; &lt;link href=&quot;https://linux.die.net/man/1/play&quot;/>; &lt;author>; &lt;name>;brudgers&lt;/name>; &lt;uri>;https://news.ycombinator.com/user?id=brudgers&lt;/uri>; &lt;/author>; &lt;content type=&quot;html&quot;>;&lt;img src=&quot;https://linux.die.net/style/logo.svg&quot; style=&quot;width: 220px; height: 220px;&quot; />;&lt;br />;SoX is a command-line audio processing tool that can read and write audio files in most popular formats, apply effects, combine multiple input sources, synthesise audio, and act as a general purpose audio player or a multi-track audio recorder. It also has limited ability to split the input into multiple output files. SoX is particularly suited to making quick, simple edits and to batch processing. &lt;a href=&quot;https://hackernews.betacat.io/#play-1-linux-manual-page&quot; target=&quot;_blank&quot;>;[summary]&lt;/a>; &lt;a href=&quot;https://news.ycombinator.com/item?id=36256931&quot; target=&quot;_blank&quot;>;[comments]&lt;/a>;&lt;/content>; &lt;/entry>; &lt;entry xml:base=&quot;https://hackernews.betacat.io/feed.xml&quot;>; &lt;title type=&quot;text&quot;>;The computer graphics industry got started at the university of Utah&lt;/stitle>; &lt;id>;https://spectrum.ieee.org/history-of-computer-graphics-industry&lt;/id>; &lt;updated>;2023-06-10T04:01:31.040428Z&lt;/updated>; &lt;link href=&quot;https://spectrum.ieee.org/history-of-computer-graphics-industry&quot;/>; &lt;author>; &lt;name>;sohkamyung&lt;/name>; &lt;uri>;https://news.ycombinator.com/user?id=sohkamyung&lt;/uri>; &lt;/author>; &lt;content type=&quot;html&quot;>;&lt;img src=&quot;https://spectrum.ieee.org/media-library/a-large-group-of-older-men-standing-for-a-group-portrait-some-sitting-on-chairs-in-front-and-others-standing-behind-them.jpg?id=34017358&amp;width=1200&amp;height=900&quot; style=&quot;width: 220px; height: 165px;&quot; />;&lt;br />;The computer graphics industry owes much of its development to the pioneering work of David Evans and Ivan E. Sutherland, who conducted groundbreaking research at the University of Utah in the 1960s and &#39;70s. Their work helped to jump-start the industry, which now relies heavily on computer graphics and visualization techniques to create popular movies and TV shows. &lt;a href=&quot;https://hackernews.betacat.io/#the-computer-graphics-industry-got-started-at-the-university-of-utah&quot; target=&quot;_blank&quot;>;[summary]&lt;/a>; &lt;a href=&quot;https://news.ycombinator.com/item?id=36264744&quot; target=&quot;_blank&quot;>;[comments]&lt;/a>;&lt;/content>; &lt;/entry>; &lt;entry xml:base=&quot;https://hackernews.betacat.io/feed.xml&quot;>; &lt;title type=&quot;text&quot;>;Arrested for using Linux and encryption in France [video]&lt;/stitle>; &lt;id>;https://www.youtube.com/watch?v=cyFL7KJGcC0&lt;/id>; &lt;updated>;2023-06-10T23:01:31.040819Z&lt;/updated>; &lt;link href=&quot;https://www.youtube.com/watch?v=cyFL7KJGcC0&quot;/>; &lt;author>; &lt;name>;xqcgrek2&lt;/name>; &lt;uri>;https://news.ycombinator.com/user?id=xqcgrek2&lt;/uri>; &lt;/author>; &lt;content type=&quot;html&quot;>;&lt;iframe src=&quot;//www.youtube.com/embed/cyFL7KJGcC0&quot; frameborder=&quot;0&quot; allowfullscreen loading=&quot;lazy&quot;>;&lt;/iframe>; &lt;a href=&quot;https://hackernews.betacat.io/#arrested-for-using-linux-and-encryption-in-france-video&quot; target=&quot;_blank&quot;>;[summary]&lt;/a>; &lt;a href=&quot;https://news.ycombinator.com/item?id=36275795&quot; target=&quot;_blank&quot;>;[comments]&lt;/a>;&lt;/content>; &lt;/entry>; &lt;entry xml:base=&quot;https://hackernews.betacat.io/feed.xml&quot;>; &lt;title type=&quot;text&quot;>;Django Views – The Right Way&lt;/stitle>; &lt;id>;https://spookylukey.github.io/django-views-the-right-way/index.html&lt;/id>; &lt;updated>;2023-06-10T20:01:31.041166Z&lt;/updated>; &lt;link href=&quot;https://spookylukey.github.io/django-views-the-right-way/index.html&quot;/>; &lt;author>; &lt;name>;sgt&lt;/name>; &lt;uri>;https://news.ycombinator.com/user?id=sgt&lt;/uri>; &lt;/author>; &lt;content type=&quot;html&quot;>;The article is a guide to using Function Based Views (FBVs) in Django, as opposed to Class Based Views (CBVs), which have become the default way to teach and learn Django views.作者旨在提供可转移的知识，让开发人员免于学习不必要的 API。 &lt;a href=&quot;https://hackernews.betacat.io/#django-views-the-right-way&quot; target=&quot;_blank&quot;>;[summary]&lt;/a>; &lt;a href=&quot;https://news.ycombinator.com/item?id=36273892&quot; target=&quot;_blank&quot;>;[comments]&lt;/a>;&lt;/content>; &lt;/entry>; &lt;entry xml:base=&quot;https://hackernews.betacat.io/feed.xml&quot;>; &lt;title type=&quot;text&quot;>;Deep dive: how Big Ambitions hit it big on Steam&lt;/stitle>; &lt;id>;https://newsletter.gamediscover.co/p/deep-dive-how-big-ambitions-hit-it&lt;/id>; &lt;updated>;2023-06-10T21:01:31.041512Z&lt;/updated>; &lt;link href=&quot;https://newsletter.gamediscover.co/p/deep-dive-how-big-ambitions-hit-it&quot;/>; &lt;author>; &lt;name>;not-now&lt;/name>; &lt;uri>;https://news.ycombinator.com/user?id=not-now&lt;/uri>; &lt;/author>; &lt;content type=&quot;html&quot;>;&lt;img src=&quot;https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff49c7f8e-a5fc-44f9-9aa9-818fea43137f_800x448.jpeg&quot; style=&quot;width: 220px; height: 124px;&quot; />;&lt;br />;Big Ambitions 是一款由 Hovgaard Games 开发的抢先体验企业家模拟游戏，在 Steam 上大受欢迎，在大约 20 天内获得了超过 3,700 条压倒性的好评，并售出了 163,000 套。游戏的深度和复杂性，以及游戏机制的独特融合，促成了它的成功。 &lt;a href=&quot;https://hackernews.betacat.io/#deep-dive-how-big-ambitions-hit-it-big-on-steam&quot; target=&quot;_blank&quot;>;[summary]&lt;/a>; &lt;a href=&quot;https://news.ycombinator.com/item?id=36267318&quot; target=&quot;_blank&quot;>;[comments]&lt;/a>;&lt;/content>; &lt;/entry>; &lt;entry xml:base=&quot;https://hackernews.betacat.io/feed.xml&quot;>; &lt;title type=&quot;text&quot;>;How Folklore Goes Digital&lt;/stitle>; &lt;id>;https://www.return.life/p/how-folklore-goes-digital&lt;/id>; &lt;updated>;2023-06-10T20:01:31.041851Z&lt;/updated>; &lt;link href=&quot;https://www.return.life/p/how-folklore-goes-digital&quot;/>; &lt;author>; &lt;name>;related&lt;/name>; &lt;uri>;https://news.ycombinator.com/user?id=related&lt;/uri>; &lt;/author>; &lt;content type=&quot;html&quot;>;&lt;img src=&quot;https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbe2aefef-3c28-4cdb-8785-99deb2b38774_1312x928.png&quot; style=&quot;width: 220px; height: 156px;&quot; />;&lt;br />;文章讨论了都市传说的概念及其与真理和信仰的关系。它探讨了人们对错误信息的情绪反应，以及保持干净和可用的知识共享的重要性。这篇文章还探讨了备忘录在民间传说中的作用，以及它们如何在数字时代转变为传奇。 &lt;a href=&quot;https://hackernews.betacat.io/#how-folklore-goes-digital&quot; target=&quot;_blank&quot;>;[summary]&lt;/a>;&lt;/content>; &lt;/entry>; &lt;/feed>;